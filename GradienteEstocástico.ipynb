{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradienteEstocástico.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabazer/tao-fing/blob/master/GradienteEstoc%C3%A1stico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxNP2uruteMQ"
      },
      "source": [
        "# Import packages.\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import pylab as pl\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyHK-cAGeFGw"
      },
      "source": [
        "En este último notebook volvemos al método más sencillo de optimización, descenso por gradiente, pero agregamos ruido modelado como variables aleatorias o procesos estocásticos.\n",
        "\n",
        "El resultante es un método para diseñar algoritmos que procesen datos aleatorios recursivamente, y es base de tres familias de algoritmos de aprendizaje automático\n",
        "\n",
        "1) Reinforcement learning\n",
        "\n",
        "2) Neural networks\n",
        "\n",
        "3) Linear mean square filters\n",
        "\n",
        "En este caso tenemos que la función a minimizar es la esperanza de una función aleatoria\n",
        "\n",
        "$$f(\\theta)=E_{\\xi}\\left[F(\\theta,\\xi)\\right]$$\n",
        "\n",
        "donde $\\xi$ es la variable aleatoria, y $\\theta$ la variable determinística que \n",
        "queremos obtener.\n",
        "\n",
        "Luego queremos resolver \n",
        "\n",
        "\\begin{align}\n",
        "\\min_{\\theta\\in \\mathcal \\Theta}& f(\\theta)\\\\\n",
        "=\\min_{\\theta\\in  \\Theta}& E_{\\xi}\\left[F(\\theta,\\xi)\\right]\\\\\n",
        "=\\min_{\\theta\\in  \\Theta}& \\int p(\\xi)F(\\theta,\\xi) d\\xi\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Si aplicamos descenso por gradiente a este problema tenemos \n",
        "\n",
        "\\begin{align}\n",
        "\\theta^{k+1}&=\\theta^k+\\alpha_k \\nabla_\\theta f(\\theta^k)\\\\\n",
        "\\theta^{k+1}&=\\theta^k+\\alpha_k \\nabla_\\theta E_{\\xi}\\left[F(\\theta,\\xi)\\right]\n",
        "\\end{align}\n",
        "\n",
        "Si pudieramos calcular la esperanza, entonces simplemente corremos el algoritmo de arriba. \n",
        "\n",
        "Si en cambio tenemos una muestra de la variable aleatoria $w^k$, o mejor el del gradiente estocástico entonces podemos simplemente tirar la esperanza y usar una muestra\n",
        "\n",
        "\\begin{align}\n",
        "\\hat \\theta^{k+1}&=\\hat \\theta^k+\\alpha_k \\nabla_\\theta  F(\\theta^k,\\xi^k)\n",
        "\\end{align}\n",
        "\n",
        "Idea, el gradiente es un acumulador que acumula promedios recursivamente, y estos aproximan la esperanza \n",
        "\n",
        "De hecho uno no tiene por qué quedarse con una sola muestra y puede hacer bacth stochastic gradient descent\n",
        "\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\hat \\theta^{k+1}&=\\hat \\theta^k+\\alpha_k \\sum_{n=1}^N \\nabla_\\theta  F(\\theta^k,\\xi^k_n)\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "Es algoritmo de SGD corresponde a usar una sola muestra por iteración  $N=1$\n",
        "\n",
        "Ejemplo\n",
        "\n",
        "$$y=A\\theta_0+\\xi, \\text{ con } \\xi_i\\sim \\mathcal N(0,\\sigma^2),\\ i=1,2$$\n",
        "\n",
        "Queremos resolver\n",
        "\n",
        "\\begin{align}\n",
        "\\min_{\\theta\\in \\mathbb R^2}E\\left[||A\\theta -y||^2\\right]\n",
        "\\end{align}\n",
        "\n",
        "El gradiente es \n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "E\\left[2A^TA\\theta -2A^Ty\\right]\n",
        "\\end{align}\n",
        "\n",
        "El gradiente estocástico\n",
        "\n",
        "\\begin{align}\n",
        "2A^TA\\theta -2A^Ty\n",
        "\\end{align}\n",
        "\n",
        "para ello necesitamos muestras de la variable aleatoria $y$\n",
        "\n",
        "Entonces corremos\n",
        "\\begin{align}\n",
        "\\hat \\theta^{k+1}&=\\hat \\theta^k+\\alpha_k\\left(2A^TA\\theta^k -2A^Ty^k\\right) \n",
        "\\end{align}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXMhF2-onCjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7dd016a3-38bb-4d85-b44a-3d89389f074e"
      },
      "source": [
        "sigma=2\n",
        "#sigma=0\n",
        "A=[[2, 1],\n",
        "   [1, 2]]\n",
        "I=[[1, 0],\n",
        "   [0, 1]]\n",
        "AT=np.transpose(A)\n",
        "ATA=np.dot(AT,A)\n",
        "theta_0=np.transpose([1,1])\n",
        "trayectoria0=np.array([])\n",
        "trayectoria1=np.array([])\n",
        "theta=np.array([0,0])\n",
        "for k in np.arange(500):\n",
        "    trayectoria0=np.append(trayectoria0,theta[0])\n",
        "    trayectoria1=np.append(trayectoria1,theta[1])\n",
        "    alpha=1/(10*k**2+1000)\n",
        "    #alpha=1/(1000)\n",
        "    xi = np.random.normal(0, sigma, 2)\n",
        "    y=np.dot(A,theta_0)+xi;\n",
        "    gradiente_estocastico=2*np.dot(ATA,theta)-2*np.dot(AT,y)\n",
        "    theta=theta-alpha*gradiente_estocastico;\n",
        "pl.plot(trayectoria0,trayectoria1,'bo-')\n",
        "pl.xlim(0, 2)\n",
        "pl.ylim(0, 2)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 2.0)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}